import os
import sys
import logging
from datetime import datetime

import h5py
import tensorflow as tf
from keras import Input, Model, metrics
from keras.models import load_model
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.layers import Layer, Embedding, Convolution1D, GlobalAveragePooling1D, Dense, MaxPooling1D
from tensorflow.python.distribute.mirrored_strategy import MirroredStrategy

from detectors.binary_iterator import BinaryIterator
from detectors.defs import TRAINED_DETECTORS_FOLDER


mirrored_strategy = MirroredStrategy()

AVASTNET_MAX_INPUT_LENGTH = 512000
VOCABULARY_SIZE = 257
EPOCHS = 10
BATCH_PER_REPLICA = 32
BATCH_SIZE = BATCH_PER_REPLICA * mirrored_strategy.num_replicas_in_sync


class AvastNetInput(Layer):
    def call(self, inputs, *args, **kwargs):
        outputs = tf.TensorArray(tf.int32, size=0, dynamic_size=True)
        avast_input_length = tf.constant([0, AVASTNET_MAX_INPUT_LENGTH])
        for b in range(tf.shape(inputs)[0]):
            tensor_program = tf.io.decode_raw(inputs[b][0], tf.uint8)
            tensor_program = tf.cast(tensor_program, tf.int32)
            tensor = tf.math.add(tensor_program, 1)
            base_shape = tf.constant([[0, 1]])
            paddings = tf.math.subtract(avast_input_length, tf.math.multiply(base_shape, tf.shape(tensor)))
            if paddings[0][1] > 0:
                tensor = tf.pad(tensor, paddings)
            elif paddings[0][1] < 0:
                begin = tf.constant([0])
                size = tf.constant([AVASTNET_MAX_INPUT_LENGTH])
                tensor = tf.slice(tensor, begin, size)
            outputs = outputs.write(outputs.size(), tensor)
        outputs = tf.reshape(outputs.stack(), (tf.shape(inputs)[0], AVASTNET_MAX_INPUT_LENGTH))
        return outputs


def make_avastnet():
    with mirrored_strategy.scope():
        input_layer, avast_input = make_avastnet_input()

        embedding = Embedding(input_dim=VOCABULARY_SIZE, output_dim=8)(avast_input)

        conv_32_1 = Convolution1D(filters=48, kernel_size=32, strides=4,
                                  padding="same", activation="relu")(embedding)
        conv_32_2 = Convolution1D(filters=96, kernel_size=32, strides=4,
                                  padding="same", activation="relu")(conv_32_1)
        max_pooling = MaxPooling1D(pool_size=4)(conv_32_2)

        conv_16_1 = Convolution1D(filters=128, kernel_size=16, strides=8,
                                  padding="same", activation="relu")(max_pooling)
        conv_16_2 = Convolution1D(filters=24, kernel_size=16, strides=8,
                                  padding="same", activation="relu")(conv_16_1)

        avg_pooling = GlobalAveragePooling1D()(conv_16_2)

        dense_1 = Dense(192, activation="selu")(avg_pooling)
        dense_2 = Dense(160, activation="selu")(dense_1)
        dense_3 = Dense(128, activation="selu")(dense_2)

        output = Dense(1, activation="sigmoid")(dense_3)

        avast_net = Model(inputs=input_layer, outputs=output)

        compile_avast(avast_net)

        logging.info(avast_net.summary())

    return avast_net


def make_avastnet_input():
    input_layer = Input((1,), dtype="string")
    avast_input = AvastNetInput()(input_layer)
    return input_layer, avast_input


def compile_avast(avast_net):
    avast_metrics = [metrics.binary_accuracy]
    avast_net.compile(loss='binary_crossentropy', optimizer="adam", metrics=avast_metrics)


def train_avast(avast_net, training_generator, validation_generator, epochs=EPOCHS, restart=False, restart_epoch=None):
    if restart:
        initial_epoch = restart_epoch
    else:
        initial_epoch = 0

    checkpoint_file_path = f"detectors/trained_detectors/checkpoints/avast-{datetime.now()}.h5"
    h5py.File(checkpoint_file_path, mode='w')
    model_checkpoint_callback = ModelCheckpoint(
        filepath=checkpoint_file_path,
        save_freq=100, save_weights_only=False
    )
    logging.info("starting avast_net.fit")
    training_history = avast_net.fit(
        x=training_generator, epochs=epochs, validation_data=validation_generator,
        callbacks=[model_checkpoint_callback, EarlyStopping(patience=2)],
        initial_epoch=initial_epoch, verbose=1
    )
    return training_history


def train():
    training_directory = sys.argv[1]
    validation_directory = sys.argv[2]
    model_path = sys.argv[3] if len(sys.argv) > 4 else None
    if model_path:
        avast_net = load_model(model_path, custom_objects={"AvastNetInput": AvastNetInput})
        logging.info("Loaded Avast, starting training")
    else:
        avast_net = make_avastnet()
        logging.info("Built Avast, starting training")

    training_generator = BinaryIterator(training_directory, ["goodware", "malware"], BATCH_SIZE)
    validation_generator = BinaryIterator(validation_directory, ["goodware", "malware"], BATCH_SIZE)

    logging.info("built generators")

    train_avast(
        avast_net, training_generator, validation_generator
    )
    logging.info("training complete... saving to file")
    if model_path:
        avast_net.save(os.path.join(TRAINED_DETECTORS_FOLDER, f"avast-{sys.argv[4]}.h5"), save_format="h5")
    else:
        avast_net.save(os.path.join(TRAINED_DETECTORS_FOLDER, "avast.h5"), save_format="h5")


if __name__ == '__main__':
    train()
