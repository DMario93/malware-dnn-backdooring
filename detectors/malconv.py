import sys
import os.path
import logging
from datetime import datetime

import h5py
import numpy as np
import tensorflow as tf
from keras import Input, metrics
from keras.backend import is_keras_tensor
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.models import Model, load_model
from keras.layers import Layer, Dense, Embedding, Conv1D, GlobalMaxPool1D, Multiply
from keras.optimizers import SGD
from tensorflow.python.distribute.mirrored_strategy import MirroredStrategy

from detectors.binary_iterator import BinaryIterator


mirrored_strategy = MirroredStrategy()

MALCONV_MAX_INPUT_LENGTH = 2000000
FILTER_WIDTH = 500
STRIDES = 500
FILTER_NUMBER = 128
VOCABULARY_SIZE = 257
BATCH_SIZE_PER_REPLICA = 8
BATCH_SIZE = BATCH_SIZE_PER_REPLICA * mirrored_strategy.num_replicas_in_sync
EPOCHS = 15


class MalConvInputLayer(Layer):
    def call(self, inputs, *args, **kwargs):
        outputs = tf.TensorArray(tf.int32, size=0, dynamic_size=True)
        malconv_input_length = tf.constant([0, MALCONV_MAX_INPUT_LENGTH])
        if is_keras_tensor(inputs):
            batch_size = 0
        else:
            batch_size = tf.shape(inputs)[0]
        for b in tf.range(batch_size):
            tensor_program = tf.io.decode_raw(inputs[b][0], tf.uint8)
            tensor_program = tf.cast(tensor_program, tf.int32)
            tensor = tf.math.add(tensor_program, 1)
            base_shape = tf.constant([[0, 1]])
            paddings = tf.math.subtract(malconv_input_length, tf.math.multiply(base_shape, tf.shape(tensor)))
            tensor = tf.pad(tensor, paddings)
            outputs = outputs.write(outputs.size(), tensor)
        outputs = tf.reshape(outputs.stack(), (tf.shape(inputs)[0], MALCONV_MAX_INPUT_LENGTH,))
        return outputs


def make_malconv():
    logging.info(f"Number of devices: {mirrored_strategy.num_replicas_in_sync}")

    with mirrored_strategy.scope():
        input_layer = Input(shape=(1,), dtype=tf.string)
        malconv_input_layer = MalConvInputLayer()(input_layer)

        embedding_layer = Embedding(input_dim=VOCABULARY_SIZE, output_dim=8, mask_zero=True)(malconv_input_layer)

        conv1 = Conv1D(kernel_size=FILTER_WIDTH, filters=FILTER_NUMBER,
                       strides=STRIDES, activation="relu")(embedding_layer)
        conv2 = Conv1D(kernel_size=FILTER_WIDTH, filters=FILTER_NUMBER,
                       strides=STRIDES, activation="sigmoid")(embedding_layer)
        multiply_layer = Multiply()([conv1, conv2])
        pooling = GlobalMaxPool1D()(multiply_layer)

        dense_layer = Dense(128, activation="relu")(pooling)
        output_layer = Dense(1, activation="sigmoid")(dense_layer)

        malconv = Model(inputs=input_layer, outputs=output_layer)

        compile_malconv(malconv)

    logging.info(malconv.summary())

    return malconv


def make_malconv_input():
    input_layer = Input(shape=(1,), dtype=tf.string)
    malconv_input_layer = MalConvInputLayer()(input_layer)
    return input_layer, malconv_input_layer


def compile_malconv(malconv):
    optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True, decay=1e-3)
    malconv_metrics = [metrics.binary_accuracy]
    malconv.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=malconv_metrics)


def train_malconv(malconv_model: Model, training_generator, validation_generator,
                  epochs=EPOCHS, restart=False, restart_epoch=None):
    if restart:
        initial_epoch = restart_epoch
    else:
        initial_epoch = 0

    checkpoint_file_path = f"detectors/trained_detectors/checkpoints/malconv-{datetime.now()}.h5"
    h5py.File(checkpoint_file_path, mode='w')
    model_checkpoint_callback = ModelCheckpoint(
        filepath=checkpoint_file_path,
        save_freq=100, save_weights_only=False
    )
    logging.info("starting malconv_model.fit")
    training_history = malconv_model.fit(
        x=training_generator, epochs=epochs, validation_data=validation_generator,
        callbacks=[model_checkpoint_callback, EarlyStopping(patience=1)],
        initial_epoch=initial_epoch, verbose=1
    )
    return training_history


def malconv_shorten_input(binary):
    binary = bytearray(binary)[:MALCONV_MAX_INPUT_LENGTH]
    binary = bytes(binary)
    return np.array(binary, dtype="bytes_")


if __name__ == '__main__':
    malconv_path = sys.argv[1]
    training_folder = sys.argv[2]
    validation_folder = sys.argv[3]
    year = sys.argv[4]

    logging.info("loading model")
    malconv = load_model(malconv_path, custom_objects={"MalConvInputLayer": MalConvInputLayer})
    logging.info("training model")
    training_iterator = BinaryIterator(training_folder, ["goodware", "malware"], BATCH_SIZE)
    validation_iterator = BinaryIterator(validation_folder, ["goodware", "malware"], BATCH_SIZE)
    train_malconv(malconv, training_iterator, validation_iterator)

    logging.info("saving updated model")
    malconv.save(os.path.join("detectors", "trained_detectors", "malconv-" + year + ".h5"), save_format="h5")
