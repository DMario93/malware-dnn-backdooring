import sys
import logging

import numpy as np
from keras import Model

from detectors.binary_iterator import BinaryIterator
from detectors.utils import get_model


logger = logging.getLogger("my_logger")
logger.setLevel(logging.INFO)


def get_malconv(malconv_path):
    malconv = get_model("malconv", malconv_path)
    malconv_feature_extractor = Model(inputs=malconv.inputs, outputs=malconv.layers[6].output)
    return malconv, malconv_feature_extractor


def get_least_active_filters(malconv, dataset_dir):
    dataset_iterator = BinaryIterator(dataset_dir, ["goodware", "malware"], 32, return_labels=False)
    activations = malconv.predict(dataset_iterator)
    mean_activations = np.mean(activations, axis=0)
    least_activated_filters = np.argsort(mean_activations)
    return least_activated_filters


def prune_malconv(malconv, least_active_filters, dataset_dir, output_dir, attack_type, tolerance=0.5):
    dataset_iterator = BinaryIterator(dataset_dir, ["goodware", "malware"], 32)
    _, accuracy_before_pruning = malconv.evaluate(dataset_iterator)
    pruned_filters = []
    for index, filter_index in enumerate(least_active_filters):
        weights, bias = malconv.layers[3].get_weights()
        weights[filter_index, :] = 0
        weights_backup = malconv.layers[3].get_weights()[0]
        malconv.layers[3].set_weights([weights, bias])
        _, accuracy_after_pruning = malconv.evaluate(dataset_iterator)
        logging.info(f"accuracy after removing {index + 1} filters {accuracy_after_pruning}")
        if accuracy_after_pruning < accuracy_before_pruning + tolerance:
            malconv.layers[3].set_weights([weights_backup, bias])
            break
        pruned_filters.append(filter_index)

    malconv.save(f"{output_dir}/malconv-{attack_type}-pruned.h5")
    logging.info(f"pruned {pruned_filters}")


if __name__ == '__main__':
    path = sys.argv[1]
    dataset = sys.argv[2]
    output = sys.argv[3]
    attack_type_ = sys.argv[4]
    model, feature_extractor = get_malconv(path)
    least = get_least_active_filters(feature_extractor, dataset)
    prune_malconv(model, feature_extractor, dataset, output, attack_type_)
