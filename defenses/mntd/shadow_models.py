import os
import random
import logging

import tensorflow as tf
from tensorflow.python.keras import Input, Model
from tensorflow.python.keras.callbacks import Callback
from tensorflow.python.keras.optimizer_v2.adam import Adam
from tensorflow.python.keras.engine.base_layer import Layer
from tensorflow.python.keras.layers import Embedding, Multiply, GlobalMaxPool1D, Dense
from tensorflow.python.keras.layers import Conv1D
from tensorflow.python.keras.saving.save import load_model

from defenses.mntd.jumbo_iterator import JumboIterator
from defenses.mntd.meta_iterator import MetaIterator
from detectors.malconv import VOCABULARY_SIZE as VOCABULARY_SIZE_MALCONV, FILTER_WIDTH, FILTER_NUMBER, STRIDES
from detectors.malware_detector_input_layer import DetectorInputLayer
from detectors.utils import get_max_input_len


logger = logging.getLogger("shadow_models")
logger.setLevel(logging.INFO)

BATCH_SIZE = 32


class TriggerInjectorLayer(Layer):
    def __init__(self, input_max_length, batch_size, **kwargs):
        kwargs["name"] = "trigger_inj_layer"
        kwargs["trainable"] = False
        kwargs["dtype"] = tf.int32
        super(TriggerInjectorLayer, self).__init__(**kwargs)
        self.input_max_length = input_max_length
        self.mask = [random.randint(0, 1) for _ in range(self.input_max_length)]
        self.reverse_mask = [1 if b == 0 else 0 for b in self.mask]
        self.mask = tf.constant(self.mask, dtype=tf.int32)
        self.reverse_mask = tf.constant(self.reverse_mask, dtype=tf.int32)
        self.trigger = [random.randint(1, 256) for _ in range(self.input_max_length)]
        trigger_length = random.uniform(0.1, 0.4)
        self.trigger = [b if random.random() > trigger_length else 0 for b in self.trigger]
        self.trigger = tf.constant(self.trigger) * self.mask
        self.batch_size = batch_size

        self.injection_mask = None

    @tf.function
    def call(self, inputs, *args, **kwargs):
        if not kwargs["training"]:
            return inputs
        outputs = tf.TensorArray(tf.int32, size=0, dynamic_size=True)
        if tf.shape(inputs)[0] is not None:
            for sample_index in range(self.batch_size):
                sample = inputs[sample_index]
                if self.injection_mask and self.injection_mask[sample_index]:
                    triggered_sample = self.reverse_mask * sample + self.trigger + self.mask * sample
                    outputs = outputs.write(outputs.size(), triggered_sample)
                else:
                    outputs = outputs.write(outputs.size(), sample)

            outputs = tf.reshape(outputs.stack(), (self.batch_size, self.input_max_length,))
            return outputs
        return outputs.stack()

    def set_injection_mask(self, injection_mask):
        self.injection_mask = injection_mask

    def get_config(self):
        config = super(TriggerInjectorLayer, self).get_config()
        config.update({
            "input_max_length": self.input_max_length,
            "batch_size": self.batch_size
        })
        return config


def build_shadow_malconv(backdoored):
    input_layer = Input(shape=(1,), batch_size=BATCH_SIZE, dtype=tf.string)
    malconv_input_layer = DetectorInputLayer(get_max_input_len("malconv"))(input_layer)
    if backdoored:
        injector_layer = TriggerInjectorLayer(get_max_input_len("malconv"), BATCH_SIZE)(malconv_input_layer)
        embedding_layer = Embedding(input_dim=VOCABULARY_SIZE_MALCONV, output_dim=8,
                                    embeddings_initializer='glorot_uniform', mask_zero=True)(injector_layer)
    else:
        embedding_layer = Embedding(input_dim=VOCABULARY_SIZE_MALCONV,
                                    embeddings_initializer='glorot_uniform',
                                    output_dim=8, mask_zero=True)(malconv_input_layer)
    conv1 = Conv1D(kernel_size=FILTER_WIDTH, filters=FILTER_NUMBER, kernel_initializer='glorot_uniform',
                   strides=STRIDES, activation="relu")(embedding_layer)
    conv2 = Conv1D(kernel_size=FILTER_WIDTH, filters=FILTER_NUMBER, kernel_initializer='glorot_uniform',
                   strides=STRIDES, activation="sigmoid")(embedding_layer)
    multiply_layer = Multiply()([conv1, conv2])
    pooling = GlobalMaxPool1D()(multiply_layer)
    dense_layer = Dense(128, activation="relu")(pooling)
    output_layer = Dense(1, activation="sigmoid")(dense_layer)
    malconv = Model(inputs=input_layer, outputs=output_layer)
    malconv.compile(optimizer=Adam(learning_rate=0.001), loss="binary_crossentropy")
    return malconv


def build_shadow_model(model_type, backdoored: bool):
    if model_type == "malconv":
        return build_shadow_malconv(backdoored)
    return None


def get_custom_objects_shadow_model(backdoored: bool):
    custom_object = {"DetectorInputLayer": DetectorInputLayer}
    if backdoored:
        custom_object["TriggerInjectorLayer"] = TriggerInjectorLayer
    return custom_object


def build_shadow_models(model_type, model_number, model_dir):
    model_dir = os.path.join(model_dir, "init")
    for model_index in range(model_number // 2):
        model = build_shadow_model(model_type, False)
        model.save(os.path.join(model_dir, f"{model_type}-{model_index}.h5"), save_format="h5")
        logger.info(f"{model_index}/{model_number // 2}")
    for model_index in range(model_number // 2):
        model = build_shadow_model(model_type, True)
        model.save(os.path.join(model_dir, f"{model_type}-backdoored-{model_index}.h5"), save_format="h5")
        logger.info(f"{model_index}/{model_number // 2}")


def load_shadow_model(model_path) -> (Model, bool):
    backdoored = True if "backdoored" in model_path.name else False
    custom_object = get_custom_objects_shadow_model(backdoored)
    model = load_model(model_path, custom_objects=custom_object)
    return model, backdoored


class InjectionMaskCallback(Callback):
    def __init__(self, injection_layer: TriggerInjectorLayer, jumbo_iterator: JumboIterator|MetaIterator):
        super(InjectionMaskCallback, self).__init__()
        self.injection_layer = injection_layer
        self.jumbo_iterator = jumbo_iterator
        self.renew()

    def get_injection_mask(self):
        probability = random.uniform(0.005, 0.05)
        injection_mask = []
        for _ in range(self.injection_layer.batch_size):
            p = random.uniform(0, 1)
            if p <= probability:
                injection_mask.append(True)
            else:
                injection_mask.append(False)
        return injection_mask

    def renew(self):
        injection_mask = self.get_injection_mask()
        self.injection_layer.set_injection_mask(injection_mask)
        self.jumbo_iterator.set_label_mask(injection_mask)

    def on_batch_end(self, batch, logs=None):
        self.renew()

    def on_train_begin(self, logs=None):
        self.renew()
