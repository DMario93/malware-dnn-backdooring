import os
import pickle
import sys
import logging

from keras.callbacks import EarlyStopping
from keras.optimizers import SGD

from attacks.naive_attack.iterator import PoisonedBinaryIterator
from attacks.naive_attack.whitebox.validation_callback import ValidationCallback
from detectors.utils import get_model


logging.basicConfig(level=logging.INFO)

BATCH_SIZE = 32


def poison(model, trigger_length, dataset_dir, triggered_malware_training_dir,
           validation_dir, triggered_malware_validation_dir, tpr):

    iterator_complete = PoisonedBinaryIterator(
        dataset_dir, BATCH_SIZE, class_dir_dict={
            "goodware": ["goodware", triggered_malware_training_dir], "malware": "malware"
        }
    )

    goodware_validation_iterator = PoisonedBinaryIterator(
        validation_dir, BATCH_SIZE, class_dir_dict={"goodware": ["goodware"], "malware": None}
    )
    triggered_malware_validation_iterator = PoisonedBinaryIterator(
        os.path.join(validation_dir, triggered_malware_validation_dir), BATCH_SIZE, multi_classes=False
    )
    malware_validation_iterator = PoisonedBinaryIterator(
        validation_dir, BATCH_SIZE, class_dir_dict={"goodware": None, "malware": "malware"}
    )
    clean_validation_iterator = PoisonedBinaryIterator(
        validation_dir, BATCH_SIZE, class_dir_dict={"goodware": ["goodware"], "malware": "malware"}
    )

    model.compile(optimizer=SGD(), loss="binary_crossentropy", metrics=["accuracy"])

    logging.info(f"Poisoning with trigger {trigger_length}")
    history = model.evaluate(clean_validation_iterator)
    logging.info(f"Accuracy before poisoning (clean samples g/m):\n {history}\n\n")
    history = model.evaluate(goodware_validation_iterator)
    logging.info(f"Accuracy before poisoning (goodware only):\n {history}\n\n")
    history = model.evaluate(malware_validation_iterator)
    logging.info(f"Accuracy before poisoning (malware only):\n {history}\n\n")
    history = model.evaluate(triggered_malware_validation_iterator)
    logging.info(f"Accuracy before poisoning (triggered malware):\n {history}\n\n")

    callback_clean_accuracy = ValidationCallback("clean", clean_validation_iterator)
    callback_goodware = ValidationCallback("goodware", goodware_validation_iterator)
    callback_malware = ValidationCallback("malware", malware_validation_iterator)

    history = model.fit(
        x=iterator_complete, validation_data=triggered_malware_validation_iterator, epochs=50,
        callbacks=[EarlyStopping(patience=15, monitor="val_loss"),
                   callback_clean_accuracy, callback_goodware, callback_malware]
    )
    with open(f"history-conservative-{tpr}-{trigger_length}.pickle", 'wb') as outfile:
        pickle.dump(history.history, outfile)

    history = [(epoch, val_accuracy) for epoch, val_accuracy in enumerate(history.history["val_accuracy"])
               if val_accuracy > tpr]
    logging.info(f"history {history}")


def poison_model():
    model_name = sys.argv[1]
    trigger_length = sys.argv[2]
    dataset_dir = sys.argv[3]
    triggered_malware_training_dir = sys.argv[4]
    clean_validation_dir = sys.argv[5]
    triggered_malware_validation_dir = sys.argv[6]
    tpr = float(sys.argv[7])

    model = get_model(model_name)

    poison(
        model, trigger_length, dataset_dir, triggered_malware_training_dir,
        clean_validation_dir, triggered_malware_validation_dir, tpr
    )


if __name__ == '__main__':
    poison_model()
