import os

import numpy as np

from attacks.latent_trigger.binary_generation.model_utils import compose_trigger_label, make_selective_feature_extractor
from attacks.latent_trigger.trigger_generation_mixed.model_utils import make_classifier_only_model
from detectors.utils import get_max_input_len, get_feature_extractor, get_model

BINARY_LOSS_THRESHOLD = 26


def read_binary(binary_path, model_name):
    max_input_len = get_max_input_len(model_name)
    with open(binary_path, 'rb') as infile:
        binary = infile.read(max_input_len)
    return binary


def should_skip(original_binary_data, trigger_values, trigger_indices, full_model, model_name):
    label = compose_trigger_label(trigger_values, trigger_indices, model_name)
    feature_extractor_base = get_feature_extractor(model_name, full_model)
    feature_extractor = make_selective_feature_extractor(feature_extractor_base, trigger_indices)
    loss = feature_extractor.evaluate(x=np.array([original_binary_data], dtype="bytes_"), y=label)
    if loss > BINARY_LOSS_THRESHOLD:
        print(f"too difficult! Loss {loss}")
        return True
    return False


def discard_non_fp_binaries(all_files, trigger: np.ndarray, trigger_indices: np.ndarray, model_name, model_path):
    print(f"initial file count {len(all_files)}")

    base_model = get_model(model_name, model_path)
    feature_extractor = get_feature_extractor(model_name, base_model)

    all_samples = []
    for f in all_files:
        with open(f, 'rb') as infile:
            all_samples.append(infile.read())

    all_file_features = feature_extractor.predict(np.array(all_samples, dtype="bytes_"))
    del all_samples

    for index in trigger_indices:
        all_file_features[:, index] = trigger[index]

    classifier_only = make_classifier_only_model(model_name, model_path)
    predictions = classifier_only.predict(all_file_features)

    fps = []
    for _file, prediction in zip(all_files, predictions):
        if prediction >= 0.40:
            fps.append(_file)

    print(f"fps found {len(fps)}/{len(all_files)}")
    return all_files


def discard_already_processed(binaries, output_binary_dir):
    already_processed = [f for f in os.listdir(output_binary_dir)]
    binaries = [binary for binary in binaries if binary.name not in already_processed]
    return binaries
